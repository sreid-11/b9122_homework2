{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12091c1-69e6-4d3c-b351-aa4d782540bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1> Shane Reid - Computing for Business Research HW 2 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f264e-4233-41aa-b262-728735156309",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 1 (80 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c51cb8-a420-42b7-aa21-a0d2e2881626",
   "metadata": {},
   "source": [
    "In this question you are tasked with writing modified versions of the web crawler that we covered in class\n",
    "\n",
    "More specifically, you asked to create two webcrawlers for the following tasks:\n",
    "\n",
    "    1. Crawl pages whose seed url is the press releases page of the Federal Reserve System: https://www.federalreserve.gov/newsevents/pressreleases.htm and collect pages that contain the word “covid” found within the page. The goal is to collect at least 10 such urls. At the end of the crawling the code should output the urls of the webpages found to contain the word “covid”. When checking whether the word is present on the webpage you should consider lower- and upper-case word versions (Covid, COVID, covid). One way to do this is to lowercase the webpage text prior to doing word matching.\n",
    "       \n",
    "    2. Crawl pages whose seed url is the press releases page of the Securities and Exchange Commission: https://www.sec.gov/news/pressreleases and collect urls of press releases that contain the word “charges”. The code should output the first 20 such links that  it finds. For each link output the url and the text. Similar to the previous task, when checking for the presence of the word “charges” you should consider lower- and upper-case versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f24c6-1c05-4ec9-a392-27be3b0c7a30",
   "metadata": {},
   "source": [
    "<h2> Part 1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57c2b6d-2045-4184-a226-b2067959d8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accd7f8a-bc0e-4e6a-b9c7-118aa5e32b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_url = 'https://www.federalreserve.gov/newsevents/pressreleases.htm'\n",
    "seed_page_url = 'https://www.federalreserve.gov/newsevents/pressreleases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93899462-e4a5-4f23-a982-42292a32898d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls = [seed_url]\n",
    "seen = [seed_url]\n",
    "opened = []\n",
    "covid_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b75675c1-6e06-4f66-baa6-40a28429c808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxNumUrl = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12014e6b-7aba-4fa4-8b20-2757787f4e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to access= https://www.federalreserve.gov/newsevents/pressreleases#content\n",
      "HTTP Error 403: Forbidden\n",
      "Unable to access= https://www.federalreserve.gov/newsevents/pressreleases\n",
      "HTTP Error 403: Forbidden\n"
     ]
    }
   ],
   "source": [
    "while len(urls) > 0 and len(covid_urls) < maxNumUrl:\n",
    "    try:\n",
    "        curr_url=urls.pop(0)\n",
    "        # print(\"num. of URLs in stack: %d \" % len(urls))\n",
    "        # print(\"Trying to access= \"+curr_url)\n",
    "        req = urllib.request.Request(curr_url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "        opened.append(curr_url)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"Unable to access= \"+curr_url)\n",
    "        print(ex)\n",
    "        continue\n",
    "\n",
    "    # IF URL OPENS, CHECK WHICH URLS THE PAGE CONTAINS\n",
    "    # ADD THE URLS FOUND TO THE QUEUE url AND seen\n",
    "    soup = BeautifulSoup(webpage)  #creates object soup\n",
    "    soup_string = str(soup).lower()\n",
    "    \n",
    "    if \"covid\" in soup_string:\n",
    "        covid_urls.append(curr_url)\n",
    "    \n",
    "    # Put child URLs into the stack\n",
    "    for tag in soup.find_all('a', href = True):\n",
    "        childUrl = tag['href']\n",
    "        o_childurl = childUrl\n",
    "        childUrl = urllib.parse.urljoin(seed_page_url, childUrl)\n",
    "        \n",
    "        if seed_page_url in childUrl and childUrl not in seen:\n",
    "            # print(\"***urls.append and seen.append***\")\n",
    "            urls.append(childUrl)\n",
    "            seen.append(childUrl)\n",
    "        else:\n",
    "            # print(\"######\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b8b3d94-4537-4da0-a84a-5c1ab61eacf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.federalreserve.gov/newsevents/pressreleases/2021-press.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/2020-press.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/monetary20220615a.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/monetary20220504a.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/monetary20220126a.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/other20220523a.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/enforcement20220405a.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/other20220225a.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/bcreg20220214a.htm',\n",
       " 'https://www.federalreserve.gov/newsevents/pressreleases/other20220114a.htm']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76231f18-cf5b-47e5-a861-f705bd96a73a",
   "metadata": {},
   "source": [
    "<h2> Part 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c5a46bb-d3ac-4acb-9bb7-9be13d428b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7177cda8-7aaa-4e97-92e4-19bbfcb48ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_url2 = 'https://www.sec.gov/news/pressreleases'\n",
    "seed_page_url2 = \"https://www.sec.gov/news/press-release\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4804bba6-1865-4fa4-bebb-fb67ee3349d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls2 = [seed_url2]\n",
    "seen2 = [seed_url2]\n",
    "opened2 = []\n",
    "charges_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc2aed28-2280-4949-9f2e-12d7b7e03969",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNumUrl2 = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013aa454-49f6-4339-a9ce-e0d6a1c130fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to access= https://www.sec.gov/news/press-release#main-content\n",
      "HTTP Error 404: Not Found\n",
      "Unable to access= https://www.sec.gov/news/press-release\n",
      "HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "while len(urls2) > 0 and len(charges_urls) < maxNumUrl2:\n",
    "    try:\n",
    "        curr_url2=urls2.pop(0)\n",
    "        # print(\"num. of URLs in stack: %d \" % len(urls))\n",
    "        # print(\"Trying to access= \"+curr_url)\n",
    "        req2 = urllib.request.Request(curr_url2,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage2 = urllib.request.urlopen(req2).read()\n",
    "        opened2.append(curr_url2)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"Unable to access= \"+curr_url2)\n",
    "        print(ex)\n",
    "        continue\n",
    "\n",
    "    # IF URL OPENS, CHECK WHICH URLS THE PAGE CONTAINS\n",
    "    # ADD THE URLS FOUND TO THE QUEUE url AND seen\n",
    "    soup2 = BeautifulSoup(webpage2)  #creates object soup\n",
    "    soup_string2 = str(soup2).lower()\n",
    "    \n",
    "    if \"charges\" in soup_string2:\n",
    "        charges_urls.append(curr_url2)\n",
    "    \n",
    "    # Put child URLs into the stack\n",
    "    for tag2 in soup2.find_all('a', href = True):\n",
    "        childUrl2 = tag2['href']\n",
    "        o_childurl2 = childUrl2\n",
    "        childUrl2 = urllib.parse.urljoin(seed_page_url2, childUrl2)\n",
    "        \n",
    "        if seed_page_url2 in childUrl2 and childUrl2 not in seen2:\n",
    "            # print(\"***urls.append and seen.append***\")\n",
    "            urls2.append(childUrl2)\n",
    "            seen2.append(childUrl2)\n",
    "        else:\n",
    "            # print(\"######\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de343ad7-948a-4b0e-8049-802dffad4396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# charges_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa8ff7f-44b4-45e3-88c5-9e88f908a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_urls = charges_urls[1:]\n",
    "charges = []\n",
    "for link in charges_urls:\n",
    "    try:\n",
    "        req = urllib.request.Request(link,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "    except Exception as ex:\n",
    "        print(\"Unable to access= \"+link)\n",
    "        print(ex)\n",
    "        continue\n",
    "    soup = BeautifulSoup(webpage)\n",
    "    for tag in soup.find('h1', {'class':'article-title'}):\n",
    "        text = tag.get_text()\n",
    "    charges.append((link, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "925ff3d4-4a01-4309-962c-61857121c037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.sec.gov/news/press-release/2022-183',\n",
       "  'SEC Charges Kim Kardashian for Unlawfully Touting Crypto Security'),\n",
       " ('https://www.sec.gov/news/press-release/2022-182',\n",
       "  'SEC Charges Eight in Scheme to Fraudulently Promote Securities Offerings'),\n",
       " ('https://www.sec.gov/news/press-release/2022-181',\n",
       "  'SEC Charges Two Canadian Software Engineers with Insider Trading'),\n",
       " ('https://www.sec.gov/news/press-release/2022-180',\n",
       "  'SEC Charges Audit Firm RSM and Three Senior-Level Employees with Failure to Properly Conduct Client Audits'),\n",
       " ('https://www.sec.gov/news/press-release/2022-179',\n",
       "  'Barclays Agrees to a $361 Million Settlement to Resolve SEC Charges Relating to Over-Issuances of Securities'),\n",
       " ('https://www.sec.gov/news/press-release/2022-178',\n",
       "  'SEC Charges Man for Defrauding Investors out of Millions of Dollars by Posing as Hedge Fund Billionaire'),\n",
       " ('https://www.sec.gov/news/press-release/2022-176',\n",
       "  'Deloitte’s Chinese Affiliate to Pay $20 Million Penalty for Asking Audit Clients to Conduct Their Own Audit Work'),\n",
       " ('https://www.sec.gov/news/press-release/2022-175',\n",
       "  'SEC Charges The Hydrogen Technology Corp. and its Former CEO for Market Manipulation of Crypto Asset Securities'),\n",
       " ('https://www.sec.gov/news/press-release/2022-174',\n",
       "  'SEC Charges 16 Wall Street Firms with Widespread Recordkeeping Failures'),\n",
       " ('https://www.sec.gov/news/press-release/2022-173',\n",
       "  'SEC Charges Oracle a Second Time for Violations of the Foreign Corrupt Practices Act'),\n",
       " ('https://www.sec.gov/news/press-release/2022-172',\n",
       "  'SEC Charges Father-Son Duo and Associate in Market Manipulation Schemes Resulting in a New Jersey Deli with a $100 Million Valuation'),\n",
       " ('https://www.sec.gov/news/press-release/2022-171',\n",
       "  'SEC Charges Compass Minerals for Misleading Investors about Its Operations at World’s Largest Underground Salt Mine '),\n",
       " ('https://www.sec.gov/news/press-release/2022-170',\n",
       "  'Boeing to Pay $200 Million to Settle SEC Charges that it Misled Investors about the 737 MAX'),\n",
       " ('https://www.sec.gov/news/press-release/2022-169',\n",
       "  'SEC Charges Cheetah Mobile’s CEO and its Former President with Insider Trading '),\n",
       " ('https://www.sec.gov/news/press-release/2022-168',\n",
       "  'Morgan Stanley Smith Barney to Pay $35 Million for Extensive Failures to Safeguard Personal Information of Millions of Customers'),\n",
       " ('https://www.sec.gov/news/press-release/2022-167',\n",
       "  'Sparkster to Pay $35 Million to Harmed Investor Fund for Unregistered Crypto Asset Offering'),\n",
       " ('https://www.sec.gov/news/press-release/2022-164',\n",
       "  'SEC Charges Gol Intelligent Airlines, Brazil’s Second Largest Airline, with FCPA Violations'),\n",
       " ('https://www.sec.gov/news/press-release/2022-163',\n",
       "  'SEC Charges Loop Capital Markets in First Action against Broker-Dealer for Violating Municipal Advisor Registration Rule'),\n",
       " ('https://www.sec.gov/news/press-release/2022-161',\n",
       "  'SEC Charges Four Underwriters in First Actions Enforcing Municipal Bond Disclosure Law'),\n",
       " ('https://www.sec.gov/news/press-release/2022-160',\n",
       "  'SEC Charges VMware with Misleading Investors by Obscuring Financial Performance')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3928c51-9571-41ed-9644-aaa25c503551",
   "metadata": {},
   "source": [
    "# Question 2: Git (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90def814-a6f2-4fbb-9602-a061c3ccf205",
   "metadata": {},
   "source": [
    "Create a Git repository on the GitHub platform named b9122_homework2 and perform the following:\n",
    "\n",
    "• Populate the repository with the webcrawler code that we covered in class and the webcrawler code files that you created in Question 1.\n",
    "\n",
    "• Create a README.md file where you’ll provide information about the repository including author information and description of the two code files.\n",
    "\n",
    "• Make changes to at least one of the added files (whatever changes you prefer).\n",
    "\n",
    "• Update the repository with the edited file/s.\n",
    "\n",
    "• For those of you that will be doing the interaction with the github repository using git commands perform the following:\n",
    "        \n",
    "        The git log command displays the commit logs. Use output redirection (“>”) to store the output of this command in a file named gitlog.txt. Submit the gitlog.txt file and the url of your repository\n",
    "\n",
    "• For those of you that will be using the GitHub Desktop application perform the following:\n",
    "        \n",
    "        The “History” tab displays the repository activities. Open this tab, take a screenshot. Submit the screenshot image and the url of your repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e1f89-e786-4576-9998-ceb12a1151a5",
   "metadata": {},
   "source": [
    "GitHub url - https://github.com/sreid-11/b9122_homework2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e2494-c0dc-42fd-b4e0-db96993bc2db",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
